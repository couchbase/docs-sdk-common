= ACID Transactions


//-------------------------- HOWTO PARTIALS ------------------------

// tag::intro[]
Couchbase Distributed xref:7.1@server:learn:data/transactions.adoc#overview[ACID (atomic, consistent, isolated, and durable)] Transactions allow applications to perform a series of database operations as a single unit -- meaning operations are either committed together or all undone.
Transactions are distributed and work across multiple documents, buckets, scopes, and collections, which can reside on multiple nodes.
// end::intro[]


// tag::requirements[]
.Single Node Cluster
[CAUTION]
====
When using a single node cluster (for example, during development), the default number of replicas for a newly created bucket is *1*.
If left at this default, all key-value writes performed with durability will fail with a {durability-exception}.
In turn, this will cause all transactions (which perform all key-value writes durably) to fail.
This setting can be changed via:

* xref:cloud:clusters:data-service/manage-buckets.adoc#add-bucket[Capella UI]
* xref:{version-server}@server:manage:manage-buckets/create-bucket.adoc#couchbase-bucket-settings[Couchbase Server UI]
* xref:{version-server}@server:cli:cbcli/couchbase-cli-bucket-create.adoc#options[Command Line]

If the bucket already exists, then the server needs to be rebalanced for the setting to take affect.
====
// end::requirements[]


// tag::config[]
The default configuration will perform all writes with the durability setting `Majority`, ensuring that each write is available in-memory on the majority of replicas before the transaction continues.
There are two higher durability settings available that will additionally wait for all mutations to be written to physical storage on either the active or the majority of replicas, before continuing.
This further increases safety, at a cost of additional latency.

CAUTION: A level of `None` is present but its use is discouraged and unsupported.
If durability is set to `None`, then ACID semantics are not guaranteed.
// end::config[]


// tag::creating[]
To create a transaction, an application must supply its logic inside a `{lambda}`, including any conditional logic required.
Once the {lambda} has successfully run to conclusion, the transaction will be automatically committed.
If at any point an error occurs, the transaction will rollback and the {lambda} may run again.
// end::creating[]


// tag::lambda-ctx[]
[[lambda-ops]]
The transaction lambda gets passed {lambda-attempt-ctx} object -- generally referred to as `ctx` in these examples.
Since the {lambda} could be rerun multiple times, it is important that it does not contain any side effects.
In particular, you should never perform regular operations on a `Collection`, such as {collection-insert}, inside the lambda.
Such operations may be performed multiple times, and will not be performed transactionally.
Instead, you should perform these operations through the `ctx` object, e.g. {ctx-insert}.

The result of a transaction is represented by a `TransactionResult` object, which can be used to expose debugging and logging information to help track what happened during a transaction.
// end::lambda-ctx[]


// tag::creating-error[]
In the event that a transaction fails, your application could run into the following errors:

* `{transaction-commit-ambiguous}`

* `{transaction-failed}`

Refer to xref:concept-docs:transactions-error-handling.adoc#transaction_errors[Error Handling] for more details on these.
// end::creating-error[]


// tag::query-perf-note[]
.Query Concurrency
NOTE: Only one query statement will be performed by the Query service at a time.
Non-blocking mechanisms can be used to perform multiple concurrent query statements, but this may result internally in some added network traffic due to retries, and is unlikely to provide any increased performance.
// end::query-perf-note[]



// tag::rbac[]
[IMPORTANT]
.Query Mode
====
When a transaction executes a query statement, the transaction enters *query mode*, which means that the query is executed with the user's query permissions.
Any *key-value* operations which are executed by the transaction _after_ the query statement are _also_ executed with the user's query permissions.
These may or may not be different to the user's data permissions; if they are different, you may get unexpected results.
====
// end::rbac[]


// tag::single-query-transactions-intro[]
Single query transactions can be useful if you need to do large, bulk-loading transactions.

The Query service maintains where required some in-memory state for each document in a transaction, that is freed on commit or rollback.
For most use-cases this presents no issue, but there are some workloads, such as bulk loading many documents, where this could exceed the server resources allocated to the service.
Solutions to this include breaking the workload up into smaller batches, and allocating additional memory to the Query service.
Alternatively, single query transaction, described here, may be used.

Single query transactions have these characteristics:

* They have greatly reduced memory usage inside the Query service.
* As the name suggests, they consist of exactly one query, and no key-value operations.

You will see reference elsewhere in Couchbase documentation to the `tximplicit` query parameter.
Single query transactions internally are setting this parameter.
In addition, they provide automatic error and retry handling.
// end::single-query-transactions-intro[]



// --------------------- CONCEPT PARTIALS ----------------------

// tag::mechanics[]
// Note: this section may end up getting removed, as the server docs are being rewritten currently
A core idea of Couchbase transactions is that an application supplies the logic for the transaction inside a _lambda_, including any conditional logic required, and the transaction is then automatically committed.
If a transient error occurs, such as a temporary conflict with another transaction, then the transaction will rollback what has been done so far and run the lambda again.
The application does not have to do these retries and error handling itself.

Each run of the lambda is called an `attempt`, inside an overall `transaction`.

=== Active Transaction Record Entries

The first mechanic is that each of these attempts adds an entry to a metadata document in the Couchbase cluster.
These metadata documents:

* Are named Active Transaction Records, or ATRs.
* Are created and maintained automatically.
* Begin with `_txn:atr-`.
* Each contain entries for multiple attempts.
* Are viewable, and _should not be modified externally_.

Each such ATR entry stores some metadata and, crucially, whether the attempt has committed or not.
In this way, the entry acts as the single point of truth for the transaction, which is essential for providing an 'atomic commit' during reads.

=== Staged Mutations

The second mechanic is that mutating a document inside a transaction, does not directly change the body of the document.
Instead, the post-transaction version of the document is staged alongside the document (technically in its xref:concept-docs:xattr.adoc[extended attributes (XATTRs)]).
In this way, all changes are invisible to all parts of Couchbase until the commit point is reached.

These staged document changes effectively act as a lock against other transactions trying to modify the document, preventing write-write conflicts.

=== Cleanup

There are safety mechanisms to ensure that leftover staged changes from a failed transaction cannot block live transactions indefinitely.
// tag::library-cleanup-process[]
These include an asynchronous cleanup process that is started with the creation of the `Transactions` object, and scans for expired transactions created by any application, on all buckets.
// end::library-cleanup-process[]
// tag::integrated-sdk-cleanup-process[]
These include an asynchronous cleanup process that is started with the first transaction, and scans for expired transactions created by any application, on the relevant collections.
// end::integrated-sdk-cleanup-process[]

The cleanup process is detailed in the xref:concept-docs:transactions-cleanup.adoc[] page.

=== Committing

Only once the lambda has successfully run to conclusion, will the attempt be committed.
This updates the ATR entry, which is used as a signal by transactional actors to use the post-transaction version of a document from its XATTRs.
Hence, updating the ATR entry is an 'atomic commit' switch for the transaction.

After this commit point is reached, the individual documents will be committed (or "unstaged").
This provides an eventually consistent commit for non-transactional actors.
// end::mechanics[]



// tag::query[]
// tag::library-begin-transaction[]
Couchbase transactions can be initiated programmatically through a library, or by using the Query service directly with `BEGIN TRANSACTION`.
The latter is intended for those using Query via the REST API, or using the Couchbase UI, and it is strongly recommended that application writers instead use the transactions library.
// end::library-begin-transaction[]
// tag::integrated-sdk-begin-transaction[]
Couchbase transactions can be initiated programmatically through the SDK, or by using the Query service directly with `BEGIN TRANSACTION`.
The latter is intended for those using Query via the REST API, or using the Couchbase UI, and it is strongly recommended that application writers instead use the SDK.
// end::integrated-sdk-begin-transaction[]
This provides these benefits:

* It automatically handles errors and retrying.
* It allows key-value operations and queries to be freely mixed.
* It takes care of issuing `BEGIN TRANSACTION`, `END TRANSACTION`, `COMMIT` and `ROLLBACK` automatically.
These become an implementation detail, and you should not use these statements inside the lambda.

The standard key-value operations are supported by the SDK: `Insert`, `Get`, `Replace`, `Remove`.

Similarly, the majority of SQL++ DML statements are permitted within a transaction. +
Specifically: `INSERT`, `UPSERT`, `DELETE`, `UPDATE`, `MERGE`, `SELECT`.

DDL statements such as `CREATE INDEX`, are not supported.

=== Query Performance Advice

This section is optional reading, and only for those looking to maximize transactions performance.

After the first query statement in a transaction, subsequent Key-Value operations in the lambda are converted into N1QL and executed by the Query service rather than the Key-Value data service.
The operation will behave identically, and this implementation detail can largely be ignored, except for these two caveats:

* These converted key-value operations are likely to be slightly slower, as the Query service is optimized for statements involving multiple documents.
Those looking for the maximum possible performance are recommended to put key-value operations before the first query in the lambda, if possible.

* Those using non-blocking mechanisms to achieve concurrency should be aware that the converted key-value operations are subject to the same parallelism restrictions mentioned above, e.g. they will not be executed in parallel by the Query service.
// end::query[]



// tag::custom-metadata-1[]
As described earlier, transactions automatically create and use metadata documents.
By default, these are created in the default collection of the bucket of the first mutated document in the transaction.
Optionally, you can instead specify a collection to store the metadata documents.
Most users will not need to use this functionality, and can continue to use the default behavior.
They are provided for these use-cases:

* The metadata documents contain, for documents involved in each transaction, the document's key and the name of the bucket, scope and collection it exists on.
In some deployments this may be sensitive data.
* You wish to remove the default collections.
Before doing this, you should ensure that all existing transactions using metadata documents in the default collections have finished.

Custom metadata collections are enabled with:
// end::custom-metadata-1[]


// tag::custom-metadata-2[]
When specified:

* Any transactions created from this `Transactions` object, will create and use metadata in that collection.
* The asynchronous cleanup started by this `Transactions` object will be looking for expired transactions only in this collection.

You need to ensure that this application has RBAC data read and write privileges to it, and should not delete the collection subsequently as it can interfere with existing transactions.
You can use an existing collection or create a new one.
// end::custom-metadata-2[]
// tag::integrated-sdk-custom-metadata-2[]
You need to ensure that the application has RBAC data read and write privileges to any custom metadata collections, and should not delete them subsequently as that can interfere with existing transactions.
You can use existing collections or create new ones.
// end::integrated-sdk-custom-metadata-2[]


// tag::concurrency[]
Couchbase transactions require a degree of co-operation from an application.
Specifically, the application should ensure that non-transactional writes are never done concurrently with transactional writes, on the same document.

This requirement is to ensure that the strong key-value performance of Couchbase was not compromised.
A key philosophy of Couchbase transactions is that you 'pay only for what you use'.

If two such writes *do* conflict then the behaviour is undefined: either write may 'win', overwriting the other.
This still applies if the non-transactional write is using CAS.

Note this only applies to _writes_.
Any non-transactional _reads_ concurrent with transactions are fine, and are at a Read Committed level.
// end::concurrency[]



// tag::error-intro[]
Couchbase transactions will attempt to resolve many errors for you, through a combination of retrying individual operations and the application's lambda.
This includes some transient server errors, and conflicts with other transactions.
// end::error-intro[]



// tag::error[]
There can be situations where total failure is indicated to the application via errors.
These situations include:

* Any error thrown by a transaction lambda, either deliberately or through an application logic bug.
* Attempting to insert a document that already exists.
* Calling {ctx-get} on a document key that does not exist (if the resultant exception is not caught).

Once one of these errors occurs, the current attempt is irrevocably failed (though the transaction may retry the lambda to make a new attempt).
It is not possible for the application to catch the failure and continue (with the exception of {ctx-get} raising an error).
Once a failure has occurred, all other operations tried in this attempt (including commit) will instantly fail.

Transactions, as they are multi-stage and multi-document, also have a concept of partial success or failure.
This is signalled to the application through the {error-unstaging-complete}, described later.

There are three exceptions that transactions can raise to an application:

* `{transaction-failed}`
* `{transaction-expired}`
* `{transaction-commit-ambiguous}`
// end::error[]



// tag::txnfailed[]
=== {transaction-failed} and {transaction-expired}

The transaction definitely did not reach the commit point.
`{transaction-failed}` indicates a fast-failure whereas `{transaction-expired}` indicates that retries were made until the timeout was reached, but this distinction is not normally important to an application and generally `{transaction-expired}` does not need to be handled individually.

Either way, an attempt will have been made to rollback all changes.
This attempt may or may not have been successful, but the results of this will have no impact on the protocol or other actors.
No changes from the transaction will be visible, both to transactional and non-transactional actors.

==== Handling

Generally, debugging exactly why a given transaction failed requires review of the logs, so it is suggested that the application log these on failure.
The application may want to try the transaction again later.
Alternatively, if transaction completion time is not a priority, then transaction timeouts (which default to 15 seconds) can be extended across the board through `{transaction-config}`.
// end::txnfailed[]



// tag::txnfailed1[]
This will allow the protocol more time to get past any transient failures (for example, those caused by a cluster rebalance).
The tradeoff to consider with longer timeouts, is that documents that have been staged by a transaction are effectively locked from modification from other transactions, until the timeout has been reached.

Note that the timeout is not guaranteed to be followed precisely.
For example, if the application were to do a long blocking operation inside the lambda (which should be avoided), then timeout can only trigger after this finishes.
Similarly, if the transaction attempts a key-value operation close to the timeout, and that key-value operation times out, then the transaction timeout may be exceeded.

=== {transaction-commit-ambiguous}

Each transaction has a 'single point of truth' that is updated atomically to reflect whether it is committed.

However, it is not always possible for the protocol to become 100% certain that the operation was successful, before the transaction expires.
This potential ambiguity is unavoidable in any distributed system; a classic example is a network failure happening just after an operation was sent from a client to a server.
The client will not get a response back and cannot know if the server received and executed the operation.

The ambiguity is particularly important at the point of the atomic commit, as the transaction may or may not have reached the commit point.  Couchbase transactions will raise `{transaction-commit-ambiguous}` to indicate this state.
It should be rare to receive this error.

If the transaction had in fact successfully reached the commit point, then the transaction will be fully completed ("unstaged") by the asynchronous cleanup process at some point in the future.
With default settings this will usually be within a minute, but whatever underlying fault has caused the `{transaction-commit-ambiguous}` may lead to it taking longer.

If the transaction had not in fact reached the commit point, then the asynchronous cleanup process will instead attempt to roll it back at some point in the future.

==== Handling

This error can be challenging for an application to handle.
As with `{transaction-failed}` it is recommended that it at least writes any logs from the transaction, for future debugging.
It may wish to retry the transaction at a later point, or extend transactional timeouts (as detailed above) to give the protocol additional time to resolve the ambiguity.

=== {txnfailed-unstaging-complete}

This boolean flag indicates whether all documents were able to be unstaged (committed).

For most use-cases it is not an issue if it is false.
All transactional actors will still read all the changes from this transaction, as though it had committed fully.
The cleanup process is asynchronously working to complete the commit, so that it will be fully visible to non-transactional actors.

The flag is provided for those rare use-cases where the application requires the commit to be fully visible to non-transactional actors, before it may continue.
In this situation the application can raise an error here, or poll all documents involved until they reflect the mutations.

If you regularly see this flag false, consider increasing the transaction timeout to reduce the possibility that the transaction times out during the commit.
// end::txnfailed1[]



// tag::cleanup[]
Transactions will try to clean up after themselves in the advent of failures.
However, there are situations that inevitably created failed, or 'lost' transactions, such as an application crash.

This requires an asynchronous cleanup task, described in this section.

== Background Cleanup

// tag::library-cleanup-buckets[]
Creating the `Transactions` object spawns a background cleanup task, whose job it is to periodically scan for expired transactions and clean them up.
It does this by scanning a subset of the Active Transaction Record (ATR) transaction metadata documents, on each bucket.
As you'll recall from <<mechanics,earlier>>, an entry for each transaction attempt exists in one of these documents.
They are removed during cleanup or at some time after successful completion.
// end::library-cleanup-buckets[]
// tag::integrated-sdk-cleanup-collections[]
The first transaction triggered by an application will spawn a background cleanup task, whose job it is to periodically scan for expired transactions and clean them up.
It does this by scanning a subset of the Active Transaction Record (ATR) transaction metadata documents, for each collection used by any transactions.
// end::integrated-sdk-cleanup-collections[]

The default settings are tuned to find expired transactions reasonably quickly, while creating negligible impact from the background reads required by the scanning process.
To be exact, with default settings it will generally find expired transactions within 60 seconds, and use less than 20 reads per second, per collection of metadata documents being checked.
This is unlikely to impact performance on any cluster, but the settings may be <<tuning-cleanup,tuned>> as desired.

All applications connected to the same cluster and running transactions will share in the cleanup, via a low-touch communication protocol on the `_txn:client-record` metadata document that will be created in each collection in the cluster involved with transaction metadata.
This document is visible and should not be modified externally as it is maintained automatically.
All ATRs will be distributed between all cleanup clients, so increasing the number of applications will not increase the reads required for scanning.

An application may cleanup transactions created by another application.

NOTE: It is important to understand that if an application is not running, then cleanup is not running.
This is particularly relevant to developers running unit tests or similar.
// end::cleanup[]



// tag::other[]
Nevertheless, you may find that you can achieve the same result with our xref:concept-docs:durability-replication-failure-considerations.adoc#durable-writes[strong durable gurarantees within a single bucket] and some re-architecture.


Currently, Distributed ACID Transactions are available for:

* The xref:1.0@cxx-txns::distributed-acid-transactions-from-the-sdk.adoc[C++ API].
* The xref:3.3@dotnet-sdk:howtos:distributed-acid-transactions-from-the-sdk.adoc[.NET SDK].
* The xref:2.4@go-sdk:howtos:distributed-acid-transactions-from-the-sdk.adoc[Go SDK].
* The xref:3.3@java-sdk:howtos:distributed-acid-transactions-from-the-sdk.adoc[Java SDK].
* The xref:4.0@nodejs-sdk:howtos:distributed-acid-transactions-from-the-sdk.adoc[node.js SDK].
// end::other[]

